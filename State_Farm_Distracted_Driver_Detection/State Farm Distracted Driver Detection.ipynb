{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b4822f",
   "metadata": {},
   "source": [
    "# State Farm Distracted Driver Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c8205",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c6249c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ultralytics\n",
    "# %pip install split-folders\n",
    "# %pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84310787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from glob import glob\n",
    "from shutil import copyfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from ultralytics import YOLO\n",
    "import splitfolders\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f481f2d4",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6be8bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "with open('../datasets/state-farm-distracted-driver-detection/driver_imgs_list.csv') as file:\n",
    "    read_file = csv.reader(file)\n",
    "    read_file = list(read_file)\n",
    "    \n",
    "    for row in read_file[1:]:\n",
    "        key = row[1]\n",
    "        if key in data:\n",
    "            data[key].append(row[2])\n",
    "        else:\n",
    "            data[key] = [row[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc9a7866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img_44733.jpg',\n",
       " 'img_72999.jpg',\n",
       " 'img_25094.jpg',\n",
       " 'img_69092.jpg',\n",
       " 'img_92629.jpg']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['c0'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c68d42fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_list = list(data.keys())\n",
    "classes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5c3952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = '../datasets/state-farm-distracted-driver-detection/imgs/'\n",
    "\n",
    "train_dir = os.path.join(dataset_folder, 'train/')\n",
    "test_dir = os.path.join(dataset_folder, 'test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3d18d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset :  22424\n",
      "Number of images in the testing dataset :  79726\n"
     ]
    }
   ],
   "source": [
    "print('Number of images in the training dataset : ', str(len(glob(train_dir+'*/*'))))\n",
    "print('Number of images in the testing dataset : ', str(len(glob(test_dir+'*'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a884b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to separate the training set and the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430f7c96",
   "metadata": {},
   "source": [
    "### Writing helper function for creating directories for training set, validation set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb19ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_directory(path):\n",
    "    for root, dirs, files in os.walk(path, topdown = False):\n",
    "        for name in files:\n",
    "            file_path = os.path.join(root, name)\n",
    "            os.remove(file_path)\n",
    "        for name in dirs:\n",
    "            dir_path = os.path.join(root, name)\n",
    "            os.rmdir(dir_path)\n",
    "    os.rmdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7afddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories(paths, subfolders):\n",
    "    for path in paths:\n",
    "        if os.path.exists(path):\n",
    "            remove_directory(path)\n",
    "        \n",
    "        for folder in subfolders:\n",
    "            subfolder_path = os.path.join(path, folder)\n",
    "            os.makedirs(subfolder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08784b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['../datasets/state-farm-distracted-driver-detection/cleaned_dataset/train',\n",
    "         '../datasets/state-farm-distracted-driver-detection/cleaned_dataset/val',\n",
    "        '../datasets/state-farm-distracted-driver-detection/cleaned_dataset/test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1368dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders = classes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaa78ca",
   "metadata": {},
   "source": [
    "### Creating Train, Val, Test folders along with sub-directories (all Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "823f4b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_directories(paths, subfolders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67a7a8",
   "metadata": {},
   "source": [
    "### Creating the cleaned dataset using the above helper functions we have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a0f7f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = [0.6, 0.2]\n",
    "\n",
    "\n",
    "for clas, images in data.items():\n",
    "    # print(len(images))\n",
    "    train_size = int(split_size[0]*len(images))\n",
    "    # print(\"Train size: \", train_size)\n",
    "    \n",
    "    test_size = int(split_size[1]*len(images))\n",
    "    #print(\"Test size: \", test_size)\n",
    "    \n",
    "    train_images = images[:train_size]\n",
    "    # print(\"Train Images Length\", len(train_images))\n",
    "    \n",
    "    val_images = images[train_size: train_size + test_size]\n",
    "    # print(\"Val Images Length\", len(val_images))\n",
    "    \n",
    "    test_images = images[train_size + test_size:]\n",
    "    # print(\"Test Images Length\", len(test_images))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for image in train_images:\n",
    "        source = os.path.join(train_dir, clas, image)\n",
    "        # print(os.path.exists(source))\n",
    "        dest = os.path.join(paths[0], clas, image)\n",
    "        copyfile(source, dest)\n",
    "    \n",
    "    for image in val_images:\n",
    "        source = os.path.join(train_dir, clas, image)\n",
    "        dest = os.path.join(paths[1], clas, image)\n",
    "        copyfile(source, dest)\n",
    "    \n",
    "    for image in test_images:\n",
    "        source = os.path.join(train_dir, clas, image)\n",
    "        dest = os.path.join(paths[2], clas, image)\n",
    "        copyfile(source, dest)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ee5443",
   "metadata": {},
   "source": [
    "### Using a better approach for creating the cleaned dataset using `splitfolders` module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d025c",
   "metadata": {},
   "source": [
    "### First deleting the cleaned dataset created usinfg the above method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56d2e275",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_directory('../datasets/state-farm-distracted-driver-detection/cleaned_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfb0fea",
   "metadata": {},
   "source": [
    "### Creating the cleaned dataset now using splitfolder module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78870775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 22424 files [00:03, 5949.75 files/s]\n"
     ]
    }
   ],
   "source": [
    "images_dir = '../datasets/state-farm-distracted-driver-detection/imgs/train'\n",
    "output_folder = '../datasets/state-farm-distracted-driver-detection/cleaned_dataset' # Note: the function will create val, train, test sub directories by itself\n",
    "split_ratio = (0.6, 0.2, 0.2)\n",
    "\n",
    "\n",
    "\n",
    "splitfolders.ratio(images_dir, output= output_folder, seed = 10, ratio= split_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9bba1c",
   "metadata": {},
   "source": [
    "Done ! Just needed one line of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aca449",
   "metadata": {},
   "source": [
    "### From now, we will be using these Directory paths for our training, validation and testing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eae4cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../datasets/state-farm-distracted-driver-detection/cleaned_dataset/train'\n",
    "val_dir = '../datasets/state-farm-distracted-driver-detection/cleaned_dataset/val'\n",
    "test_dir = '../datasets/state-farm-distracted-driver-detection/cleaned_dataset/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a7ac97",
   "metadata": {},
   "source": [
    "## Creating Image data generator Function with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16a14cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagedatageneration(train_dir, val_dir, test_dir, target_size = (256, 256), batch_size = 32):\n",
    "    train_datagen = ImageDataGenerator(rescale = 1.0 / 255,\n",
    "                                       rotation_range = 30,\n",
    "                                       width_shift_range = 0.1,\n",
    "                                       height_shift_range = 0.1,\n",
    "                                       zoom_range = 0.1,\n",
    "                                       shear_range = 0.1,\n",
    "                                       fill_mode = \"nearest\"\n",
    "                                      )\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "                                                            train_dir,\n",
    "                                                            target_size = target_size,\n",
    "                                                            class_mode = 'categorical',\n",
    "                                                            shuffle = True,\n",
    "                                                            batch_size = batch_size\n",
    "                                                        )\n",
    "    \n",
    "    \n",
    "    val_datagen = ImageDataGenerator(rescale = 1.0 / 255)\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "                                                        val_dir,\n",
    "                                                        target_size = target_size,\n",
    "                                                        class_mode = 'categorical',\n",
    "                                                        shuffle = True,\n",
    "                                                        batch_size = batch_size\n",
    "                                                    )\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "                                                        test_dir,\n",
    "                                                        target_size = target_size,\n",
    "                                                        class_mode = 'categorical',\n",
    "                                                        shuffle = False,\n",
    "                                                        batch_size = 1\n",
    "                                                      )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b76436f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "554b1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_acc', patience = 2, min_delta = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ffff6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7287e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dir = '../datasets/state-farm-distracted-driver-detection/train'\n",
    "# val_dir = '../datasets/state-farm-distracted-driver-detection/val'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                                        train_dir,\n",
    "                                                        target_size = (256, 256),\n",
    "                                                        class_mode = 'categorical',\n",
    "                                                        shuffle = True,\n",
    "                                                        batch_size = 32\n",
    "                                                    )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "                                                        val_dir,\n",
    "                                                        target_size = (256, 256),\n",
    "                                                        class_mode = 'categorical',\n",
    "                                                        shuffle = True,\n",
    "                                                        batch_size = 32\n",
    "                                                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca6fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e970a87",
   "metadata": {},
   "source": [
    "## First Model -> Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3760014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13451 images belonging to 10 classes.\n",
      "Found 4481 images belonging to 10 classes.\n",
      "Found 4492 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator, test_generator = imagedatageneration(train_dir, val_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "acfe1909",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.Sequential([\n",
    "    Flatten(input_shape = (256, 256, 3)),\n",
    "    Dense(1024, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(512, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3acb0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer = Adam(learning_rate = 0.001), loss = 'categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2546013b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 196608)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              201327616 \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1024)              4096      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201993482 (770.54 MB)\n",
      "Trainable params: 201989898 (770.53 MB)\n",
      "Non-trainable params: 3584 (14.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc1ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "315/421 [=====================>........] - ETA: 25s - loss: 2.3069 - acc: 0.1891"
     ]
    }
   ],
   "source": [
    "model1.fit(train_generator,\n",
    "                   epochs = 10,\n",
    "                   verbose = 1,\n",
    "                   validation_data = val_generator,\n",
    "                   callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510ab18d",
   "metadata": {},
   "source": [
    "## Second Model -> CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "    Conv2D(32, (3, 3), activation = 'relu', input_shape = (256, 256, 3)),\n",
    "    Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589515fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer = Adam(), loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff8ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(train_generator,\n",
    "          epochs = 20,\n",
    "          verbose = 1,\n",
    "          validation_data = val_generator,\n",
    "          callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d92d17",
   "metadata": {},
   "source": [
    "## Third Model -> VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b2c3fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretrained_model = VGG16(weights = 'imagenet', include_top = False, input_shape = (256, 256, 3))\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9445f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in pretrained_model.layers[:-5]:\n",
    "#     layer.trainable = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = pretrained_model.get_layer('block5_pool')\n",
    "last_output = last_layer.output\n",
    "\n",
    "model3 = tf.keras.models.Sequential([ \n",
    "    pretrained_model,\n",
    "    Flatten(),\n",
    "    Dense(2048, activation = 'relu'),\n",
    "    Dense(1024, activation = 'relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation = 'softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer = Adam(learning_rate = 0.005), loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb59a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.fit(train_generator,\n",
    "          steps_per_epoch = 250,\n",
    "          epochs = 20,\n",
    "          verbose = 1,\n",
    "          validation_steps = 50,\n",
    "          validation_data = val_generator,\n",
    "          callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cda422",
   "metadata": {},
   "source": [
    "## Fourth Model -> ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = ResNet50(weights = 'imagenet', include_top = False, input_shape = (256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea23432",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pretrained_model.layers[:-3]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea82bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = tf.keras.models.Sequential([ \n",
    "    pretrained_model,\n",
    "    Flatten(),\n",
    "    Dense(512, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer = Adam(learning_rate = 0.0001), loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b71c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.fit(train_generator,\n",
    "          steps_per_epoch = 250,\n",
    "          epochs = 20,\n",
    "          verbose = 1,\n",
    "          validation_steps = 50,\n",
    "          validation_data = val_generator,\n",
    "          callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eeff80",
   "metadata": {},
   "source": [
    "## Fifth Model -> Yolo v9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ce148",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = YOLO('yolov8n-cls.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitfolders.ratio(\"../datasets/state-farm-distracted-driver-detection/imgs/train\", output=\"../datasets/state-farm-distracted-driver-detection/output\", seed = 1337, ratio=(0.7, 0.15, 0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab18529",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model5.train(data = \"../datasets/state-farm-distracted-driver-detection/output\", epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6e5a94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62484b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d870e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('./runs/classify/train2/results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"./runs/classify/train2/results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45e6111",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"./runs/classify/train2/confusion_matrix_normalized.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870f3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "# path = \"../datasets/state-farm-distracted-driver-detection/output/test/c1/\"\n",
    "# actual_class = 1\n",
    "# model_weights = \"./runs/classify/train2/weights/best.pt\"\n",
    "# pred = [(path+i,model5.predict(path+i, model = model_weights)[0].probs.top1, actual_class) for i in os.listdir(path)[:45]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64081937",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "test_images_path = \"../datasets/state-farm-distracted-driver-detection/output/test/\"\n",
    "model_weights = \"./runs/classify/train2/weights/best.pt\"\n",
    "\n",
    "predicted_list = []\n",
    "\n",
    "for clas in classes:\n",
    "    image_dir = os.path.join(test_images_path, clas)\n",
    "    # print(image_dir)\n",
    "    images_list = os.listdir(image_dir)\n",
    "    # print(images_list)\n",
    "    # Class label in the form of 0 to 9\n",
    "    class_label = int(clas[-1])\n",
    "    # print(class_label)\n",
    "    for image in images_list:\n",
    "        path = os.path.join(image_dir, image)\n",
    "        # print(path)\n",
    "        y_actual = class_label\n",
    "        y_predicted = model5.predict(path, model = model_weights)[0].probs.top1\n",
    "        predicted_list.append([path, y_actual, y_predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a45b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"length of the Predicted List : \", len(predicted_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predicted_list, columns = ['Image_path', 'Y_actual', 'Y_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eb0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(df['Y_actual'], df['Y_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ba8040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
